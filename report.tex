% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt,twocolumn]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options
\usepackage{mathtools}
\usepackage{amsmath} % need this stuff for curly brackets
% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
\usepackage{authblk}
\usepackage{pdfpages}
\usepackage{wrapfig}
\usepackage{hyperref}
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

\title{Software Engineering For Industry \\ AcmeTelecom - Report}
\author[1]{Dan Demeter\thanks{dan.demeter10@imperial.ac.uk}}
\author[1]{Dan Octavian\thanks{dan.octavian10@imperial.ac.uk}}
\author[1]{Razvan Rosie\thanks{razvan.rosie10@imperial.ac.uk}}
\author[1]{Marius Telespan\thanks{marius.telespan10@imperial.ac.uk}}
\affil[1]{Department of Computing, Imperial College London}

\begin{document}
\maketitle

\begin{abstract}
This report describes a possible solution for the problem of improving user bill calculation in a telecommunication company. 
We present a new way of organising the source code in a modular design fashion, in order to improve the process of calculating user bills. Our solution makes use of the best software engineering practices, includes unit and acceptance tests.

Additionally, we have extended the initial solution by providing source code runnable on $Amazon$ $Web$ $Services$ $Elastic$ $Map$ $Reduce$ in order to deal with large sets of customers.
\newline

{\bf Keywords}: acceptance testing, unit testing, design patterns, code refactoring.
\end{abstract}


\section{Introduction}
AcmeTelecom is a telecomommunication company which is currently running calculating the pricing and billing calculations
for all of Acme's mobile phone customers in the following way: if a customer begins a call during the peak time, and the call 
continues in off-peak period, then the whole call is billed at the the peak rate. Similarly, if a customer the call starts in 
the off-peak periodand finish in the peak time, the whole call is billed as being a peak time call. Any call that overlaps the 
peak time period is charged as a peak call.


Our main task was to refactorize the code, making sure that the billing system is fair. In order to make sure that our changes works,
we added acceptance and unit tests covering the existing code.

This report is organised in the following way: {\bf Section 2} presents our implementation of the main feature of the program, which
allows to fairly compute the billings. {\bf Section 3} presents the way that the code was refactorized. 
{\bf Section 4} includes the addition features that were added. 
The fifth section gives an overview of the testing methodologies that were used durin the project, together with the testing tools.
{\bf Section 6} discusses some design decisions that we have taken.
The last part of the report offers our concluding remarks and potential improvements for the code.

\section{ACME Telecom v2}

\subsection{The Improved Cost Calculator}

The given implementation for calculating the call costs, was not taking correctly into consideration 
the $starting$ and $end$ times for a call. As a results, calls which were taking place during both $off$-$peak$ and 
$on$-$peak$ times were being charged for the entire duration with the $on$-$peak$ tariff. For example, for an $on$-$peak$
period of $7:00$ - $18:59$, a call from $20:30$ until $21:30$ would be correctly charged for $60$ minutes $\ast$
$off$-$peak$ tariff, but a call from  $18:30$ until $19:30$ would be charged incorrectly $60$ minutes $\ast$ \textbf{on-peak},
instead of $30$ minutes $\ast$ \textbf{on-peak} $+$ 30 minutes $\ast$ \textbf{off-peak}.

Our code implementation solves this problem, and the algorithm is as follows. All notations represented by big letters 
are $DateTime$ (Joda library) instances:
\begin{enumerate}
\item{For the start call ($START$), find the next peak time start or end time ( $7:00$ or $18:59$ ) and save it as $T_1$.}

\item{Next, find the last start or end on-peak time that is before the end call ($END$) and save it as $T_2$.}
\end{enumerate}

The case when $START$ and $LAST$ times are in the same peak or off-peak period is the trivial one: we compute the 
cost for the call as ($LAST$ - $START$) $\ast$ (on-peak OR off-peak) tariff. The tariff type can be easily found. 

In the other case when START and LAST times are in different zones, we calculate how many 12 hours intervals are between T1 and T2.
If that number is even, then we know that the phone call lasted $\leq$ 24 hours. So we know that 1/2 of that time the call should be 
charged with the offpeak tariff, and the other 1/2 time should be charged with the on-peak time. 
In case that number is odd, then we identify the one extra period and which tariff should be applied to it, and then for the rest of the 
even periods, we apply the tactic discussed above. 

In the end, the final cost is the total cost for the 12 hours periods + (the cost between START and T1 (C1)) + (the cost between T2 and END (C2). 
Again, for C1 and C2 we can easily identify what tariff we need to use (peak or off-peak one).

\subsection{Joda}
Also, JodaTime helped us a lot in order to manage all the complexity for handling periods of time,
translating the a date into milliseconds and subtracting 2 different Dates. 

\subsection{Printer}
In terms of generating the status of the bills for the customers, the system was directing its results to the Standard Output pipe. 
Unfortunately, the only output interface (HtmlPrinter) was generating HTML tables which were not following the W3C standards. 
Because we have decided to make our system as reliable as possible, we had to take into consideration different set-ups where our system would be running. 
For example, it could run on a server without any output attached (headless server), or for debugging purposes, 
the billing output should be easily read and p arsed from the terminal. 
By using the abstract factory design pattern, we have restructured our Output Interface as an abstract Class, 
having different classes extend it. These classes will be actual printing and formatting the results in a way suitable for the environment.
The current classes we have implemented or changed in the system are: HTMLPrinter and ConsolePrinter. HTMLPrinter is the initial implementation 
of printing the results in an HTML format. We have decided \textbf{not} to change it, because some other legacy software might be parsing the
HTML file generated by our system. This is a major risk, because we can't control what other software interacts with the current one.

Instead, for 100\% legacy compatibility, we have decided to add new Classes extending the Output Interface. 
The first one we have added is the ConsolePrinter class that is used to print the BillingSystem output in a readable format used for debugging.
This is what we have used to test our product, integrating the ConsolePrinter with the Tests we ran. Also, because mostly all new systems will be used 
part of a bigger architecture, we have decided to implement an API interface, used for our system to export its data to others systems. 





\section{Refactoring the code}

\subsection{Package Organisation}
One of the very first tasks was to reorganise the existing source code in a new way.
This was because the existing code was simplistic and not modular enough. The way that
we have proceed was to 

\begin{enumerate}
 \item{com.actelecom.calls}
 \item{com.actelecom.print}
 \item{com.actelecom.utils}
\end{enumerate}

Similarly, we have decided to organise the tests in the same manner. The unit package contains tests for:
\begin{enumerate}
 \item{com.actelecom.tests.units.calls}
 \item{com.actelecom.tests.units.print}
 \item{com.actelecom.tests.units.utils}
\end{enumerate}



\iffalse
\subsection{Handling the cyclic dependencies}
This was caused by an inner LineItem class within BillingSystem. This was required by
BillGenerator, as it was populating a data structure containing all phone calls made by
customers.
To solve this, LineItem was extracted out into the com.acmetelecom.util subpackage,
thus removing this cyclic dependency, and at the same time, evolving the overall system
towards a more reasonable structure.
\fi

\subsection{Code refurbishment}
The existing codebase was restructured to become increasingly modular. By applying con-
cepts of dependency inversion and abstraction, we decoupled these classes into packages,
each with a dedicated purpose.
This brought about many benefits, such as encouraging code reuse and making testing
convenient. Our team could now work simultaneously and asynchronously. Integration
would be almost painless, due to a clear separation of concerns, introduced by interfaces.
Ease of collaboration was also an added benefit.
Full details of external dependencies as well as an architecture diagram, are available for reference.
The project was managed using Maven, where external dependencies are specified as
artifacts in pom.xml. The main application and test code are housed in distinct subfolders,
yet test code is able to reference the Class Under Test (CUT). Test code is also composed
as hierarchical TestSuites, to selectively test different segments of the codebase. Hardcoded
constants belong in a properties file, in the respective resources folder.

\subsection{Removing the cyclic dependencies}
A cyclic dependecy was by the inner class $LineItem$, which was placed inside the $BillingSystem.java$.
The $LineItem$ was used to store customer's phone calls in a data structure.

In order to remove the cyclic dependecy, we jave created a new external class $LineItem$ placed in the 
utilities package.

\section{Extra Work}
\subsection{Elastic Map Reduce}
\emph{Elastic MapReduce} is an Amazon-based programming model used for processing very large data sets, having its behaviour inspired from the functional programming functions $map$ and $reduce$. The overall process can be described in the following ways: the input is firstly split in such that it becomes parallelizable; after this step is performed, each resulting chunk is splitted again and mapped in a specific category; finally, a reduction step is used to eliminate the duplicates in every category and concatenates the results. We think that if the number of customers for $AcmeTelecom$ will be very large, then $EMR$ can be helpful when computing the costs of conversation and generating the bills.
\begin{figure}[ht]
\includegraphics[scale=0.25]{hadoop.png}
\caption{Hadoop \cite{hadoop}}
\end{figure}

\subsection{Source code validation}
Another important aspect of software engineering is source code validation. Besides the
aforementioned high level dependency analysis, it is probably worth using tools like Lint4J
and CodePro AnalytiX to audit code, produce metrics, such as Afferent/Efferent Couplings, to measure code quality, and find similar/dead code to identify and remove redundancy, hence streamlining the codebase, in preparation for deployment to target environment.

\subsection{Documentation}
On top of the builtin javadoc tool, the JAutodoc tool was used to generate Java documentation of typical classes like the model CustomerBill for completeness.
Subsequently, additional configuration enabled styling of the resulting generated Javadocs

\section{Testing}
Testing was further augmented by importing techniques used in web applications for example, like the Selenium web browser automated testing tool, and JSoup to construct
HTML parse trees, and navigate through them using combinations of familiar jQuery-like
selectors, for better code coverage, and hence greater confidence in the final end product.

\subsection{Unit Testing}
A unit test is an automated piece of code that invokes a unit of work in the system and then checks a single assumption about
the behavior of that unit of work.\cite{JUnit} 

\subsection{Acceptance Testing}
Acceptance testing is a test conducted to determine if the requirements of a specification or contract are met. 
It may involve chemical tests, physical tests, or performance tests.

\section{Software Engineering Practices}
During the implementation stage, good Software Development practices were maintained by the members of the group. We have extensively used some of the design patterns and development methodologies that we have learned during the implementation phase.

\subsection{Project Management}
Managing the project was a crucial aspect during the project. The group had regular Scrum meetings in order to discuss the 
progress of the project, where the team-members had brainstorming sessions, draw sketches of different scenarios, looked at
what could actually be done with the existing source code and what improvements will be necessary. All decisions were taken
with the majority of the group members.

\subsection{Design Patterns Used}
During the code refactoring stage, we have made extensive use of some design pattern.
\begin{itemize}
\item{{\bf Factory pattern} defines an interface for creating a single object, but let subclasses decide which class to instantiate. Factory Method lets a class defer instantiation to subclasses (dependency injection).}
\item{{\bf Iterator pattern} provides a way to access the elements of an aggregate object sequentially without exposing its underlying representation.}
\item{{\bf Bridge pattern} decouples an abstraction from its implementation allowing the two to vary independently.}
\item{{\bf Template pattern} defines the skeleton of an algorithm in an operation, passing some of the steps to subclasses.
Template method lets subclasses redefine certain steps of an algorithm without changing the algorithm's structure.}
\end{itemize}


\subsection{Agile Development}
The group has decided to use an \emph{iterative approach} in order to add value to our project from the beginning. 
Refactoring allowed us to change the internal structure of our code without interfering with its external behaviour. While trying to reduce complexity, refactoring continuously improved the design of the source code, reducing the complexity of our task.
Communication was also a vital factor when working for this project. The strong relationship among the developers made the task both 
easier and enjoyable.

\section{Conclusion}
In conclusion, our prohect have demonstrated in this project how to go about engineering software
with a long term vision, using proper procedures, with proven techniques and tools, which
are still applicable as the software system scales as it matures over time.
From the traditional tools for any project, such as a version control system like Git, bug
or issue tracking system like Trac, and continuous integration service like TeamCity, to
the extensive suite of testing tools for supporting through the various stages of testing,
namely, Acceptance, Unit, Integration, System, and Regression, there is evidently more
that can still be done to improve this software, given sufficient resources.

For example, the code obsfucation and optimisation Java tool, ProGuard, can also be used
during live deployment, to increase the code efficiency. If resources permit, we might have
also explored other alternatives for mocking up Java objects, like jMock, EasyMock or
Mockito frameworks, as well as other acceptance testing frameworks like JBehave.
Or even further optimise our code by profiling using VisualVM, and substituting commonly
used functions for those found in the Apache Commons project, or the Google Guava
libraries, which are far more widely used or tested, thus more reliable. There could also be
the possibility to attempt dependency injection using Google Guice, to improve testability
of, and simplify deployment across different production environments.


\begin{thebibliography}{9}

\bibitem{lamport94}
  Leslie Lamport,
  \emph{\LaTeX: A Document Preparation System}.
  Addison Wesley, Massachusetts,
  2nd Edition,
  1994.

\bibitem{mockito}
  \emph{Mockito}.
  http://docs.mockito.google\\code.com/hg/org/mockito/Mockito.html  

\bibitem{JUnit}
  \emph{JUnit}.
  https://github.com/junit-team/junit/wiki

\bibitem{UncleBob}
  \emph{Design Principles and Design Patterns}.
  Robert C. Martin,
  2000

\bibitem{artUnit}
  \emph{The Art Of Unit Testing}.
  http://artofunittesting.com/definition-of-a-unit-test/

\bibitem{hadoop}
  \emph{Hadoop}.
  http://thetechmusings.files.wordpress.com/2011/\\02/hadoop-mapreduce-execution-framework.png
  
\end{thebibliography}




\end{document}          
